{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pm4py.objects.log.importer.xes import importer as xes_importer\n",
    "from pm4py.write import write_xes\n",
    "import pm4py\n",
    "import import_ipynb\n",
    "from Statsdata import (get_freq_fitness, get_duration_fitness, get_time_fitness, get_activity_freq_stats, get_activity_duration_stats, \n",
    "get_freq_hour_normalized, get_freq_position_normalized, get_position_fitness, get_trace_length_stats, get_length_fitness)\n",
    "from Mining import discovery_inductive, discovery_heuristic, conformance\n",
    "import subprocess\n",
    "import csv\n",
    "import sys\n",
    "import os\n",
    "import uuid\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "from prettytable import PrettyTable as pt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeTable(stats, title, f):\n",
    "        # Creating object\n",
    "        tt = pt([\"\"])\n",
    "        # Adding rows\n",
    "        for stat, values in stats.items():\n",
    "                tb = pt()\n",
    "                rows = []\n",
    "                if(type(values) != dict):\n",
    "                        tb.add_row([values])\n",
    "                else:\n",
    "                        for act, value in values.items():\n",
    "                                tb.add_row([act, value])\n",
    "                tt.add_row([tb.get_string(title=stat, header=False)])\n",
    "        tt.align[\"\"] = \"l\"\n",
    "        \n",
    "        f.write(tt.get_string(title=title, header=False) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_fitness_values(results, logB, conf):\n",
    "    results[\"fitness\"] = \"\"\n",
    "    logB[\"pdc:isPos\"] = \"\"\n",
    "    match conf:\n",
    "        case 1:  \n",
    "            # Fair version      \n",
    "            w_cf = 0.5\n",
    "            w_df = 0.5\n",
    "\n",
    "            for index, trace in results.iterrows():\n",
    "                cf = trace[\"ccind\"]*(w_cf/4) + trace[\"ccheu\"]*(w_cf/4) + trace[\"ccdcr\"]*(w_cf/4) + trace[\"ccpalia\"]*(w_cf/4)\n",
    "                df = trace[\"ccfreq\"]*(w_df/3) + trace[\"ccpos\"]*(w_df/3) + trace[\"cclen\"]*(w_df/3)\n",
    "                if((cf+df)>=0.6):\n",
    "                    logB.loc[logB[\"case:concept:name\"] == trace[\"id\"], \"pdc:isPos\"] = True\n",
    "                else: logB.loc[logB[\"case:concept:name\"] == trace[\"id\"], \"pdc:isPos\"] = False\n",
    "                results.loc[trace[\"id\"], \"fitness\"] = cf+df\n",
    "        case 2:\n",
    "            # More declarative version\n",
    "            # ccind\tccheu\tccdcr   ccpalia\tccfreq\tccdur\tccpos\tcclen\n",
    "            w_cf = 0.5\n",
    "            w_df = 0.5\n",
    "\n",
    "            for index, trace in results.iterrows():\n",
    "                cf = trace[\"ccind\"]*(0) + trace[\"ccheu\"]*(0) + trace[\"ccdcr\"]*(w_cf/2) + trace[\"ccpalia\"]*(w_cf/2)\n",
    "                df = trace[\"ccfreq\"]*(w_df/3) + trace[\"ccpos\"]*(w_df/3) + trace[\"cclen\"]*(w_df/3)\n",
    "                if((cf+df)>=0.6):\n",
    "                    logB.loc[logB[\"case:concept:name\"] == trace[\"id\"], \"pdc:isPos\"] = True\n",
    "                else: logB.loc[logB[\"case:concept:name\"] == trace[\"id\"], \"pdc:isPos\"] = False\n",
    "                results.loc[trace[\"id\"], \"fitness\"] = cf+df\n",
    "        case 3:\n",
    "            # More imperative\n",
    "            w_cf = 0.5\n",
    "            w_df = 0.5\n",
    "\n",
    "            for index, trace in results.iterrows():\n",
    "                cf = trace[\"ccind\"]*(w_cf/2) + trace[\"ccheu\"]*(w_cf/2) + trace[\"ccdcr\"]*(0) + trace[\"ccpalia\"]*(0)\n",
    "                df = trace[\"ccfreq\"]*(w_df/3) + trace[\"ccpos\"]*(w_df/3) + trace[\"cclen\"]*(w_df/3)\n",
    "                if((cf+df)>=0.6):\n",
    "                    logB.loc[logB[\"case:concept:name\"] == trace[\"id\"], \"pdc:isPos\"] = True\n",
    "                else: logB.loc[logB[\"case:concept:name\"] == trace[\"id\"], \"pdc:isPos\"] = False\n",
    "                results.loc[trace[\"id\"], \"fitness\"] = cf+df\n",
    "        case 4:\n",
    "            # More control flow\n",
    "            w_cf = 0.8\n",
    "            w_df = 0.2\n",
    "\n",
    "            for index, trace in results.iterrows():\n",
    "                cf = trace[\"ccind\"]*(w_cf/4) + trace[\"ccheu\"]*(w_cf/4) + trace[\"ccdcr\"]*(w_cf/4) + trace[\"ccpalia\"]*(w_cf/4)\n",
    "                df = trace[\"ccfreq\"]*(w_df/3) + trace[\"ccpos\"]*(w_df/3) + trace[\"cclen\"]*(w_df/3)\n",
    "                if((cf+df)>=0.6):\n",
    "                    logB.loc[logB[\"case:concept:name\"] == trace[\"id\"], \"pdc:isPos\"] = True\n",
    "                else: logB.loc[logB[\"case:concept:name\"] == trace[\"id\"], \"pdc:isPos\"] = False\n",
    "                results.loc[trace[\"id\"], \"fitness\"] = cf+df\n",
    "        case 5:\n",
    "            # More data flow\n",
    "            w_cf = 0.2\n",
    "            w_df = 0.8\n",
    "\n",
    "            for index, trace in results.iterrows():\n",
    "                cf = trace[\"ccind\"]*(w_cf/4) + trace[\"ccheu\"]*(w_cf/4) + trace[\"ccdcr\"]*(w_cf/4) + trace[\"ccpalia\"]*(w_cf/4)\n",
    "                df = trace[\"ccfreq\"]*(w_df/3) + trace[\"ccpos\"]*(w_df/3) + trace[\"cclen\"]*(w_df/3)\n",
    "                if((cf+df)>=0.6):\n",
    "                    logB.loc[logB[\"case:concept:name\"] == trace[\"id\"], \"pdc:isPos\"] = True\n",
    "                else: logB.loc[logB[\"case:concept:name\"] == trace[\"id\"], \"pdc:isPos\"] = False\n",
    "                results.loc[trace[\"id\"], \"fitness\"] = cf+df\n",
    "    return results, logB\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execall(path_logB, path_logA, path_models, path_output):\n",
    "    # Opening JSON file\n",
    "    with open(path_models+\".json\") as json_file:\n",
    "        discovered_models = json.load(json_file)\n",
    "    logA = xes_importer.apply(path_logA+\".xes\")\n",
    "    logB = xes_importer.apply(path_logB+\".xes\")\n",
    "    uuid = discovered_models[\"UUID\"]\n",
    "    res = pd.DataFrame()\n",
    "    PATH = 'Accepted Traces'\n",
    "    if not os.path.exists(PATH):\n",
    "        os.makedirs(PATH)\n",
    "\n",
    "    # Conformance checking (alignment) from Inductive\n",
    "    print(\"Conformance checking from Inductive...\")\n",
    "    ccind_traces, ccind = conformance(discovered_models[\"Ind\"], logB)\n",
    "    ccind_traces.to_csv(\"Accepted Traces/accepted_traces_ind_\"+uuid+\".csv\", index=False)\n",
    "    res = res.assign(ccind = ccind_traces.loc[:,\"fitness\"])\n",
    "    print(\"Done\")\n",
    "\n",
    "    # Conformance checking (alignment) from Heuristic\n",
    "    print(\"Conformance checking from Heuristic...\")\n",
    "    ccheu_traces, ccheu = conformance(discovered_models[\"Heu\"], logB)\n",
    "    ccheu_traces.to_csv(\"Accepted Traces/accepted_traces_heu_\"+uuid+\".csv\", index=False)\n",
    "    res = res.assign(ccheu = ccheu_traces.loc[:,\"fitness\"])\n",
    "    print(\"Done\")\n",
    "\n",
    "    # Conformance checking of DCR\n",
    "    # java -jar \"dcr-conformance.jar\" \"path model .JSON\" \"path logB\" open world flag\n",
    "    print(\"Conformance of DCR...\")\n",
    "    subprocess.call(['java', '-jar', 'dcr-conformance.jar', discovered_models[\"DCR\"], path_logB+\".xes\", \"FALSE\"])\n",
    "\n",
    "    # The total fitness value is saved in the file dcrcc.txt\n",
    "    f = open(\"dcrcc.txt\", \"r\")\n",
    "    for line in f:\n",
    "        ccdcr = float(line)\n",
    "    f.close()\n",
    "\n",
    "    ccdcr_traces = pd.read_csv(\"Accepted Traces/accepted_traces_dcr_\"+uuid+\".csv\", names=[\"id\",\"fitness\"])\n",
    "    res = res.assign(ccdcr = ccdcr_traces.loc[:,\"fitness\"])\n",
    "    print(\"Done\")\n",
    "\n",
    "    # Conformance checking of Palia\n",
    "    # java -jar \"palia-conformance.jar\" \"path model .JSON\" \"path logB\"\n",
    "    print(\"Conformance of Palia...\")\n",
    "    subprocess.call(['java', '-jar', 'palia-conformance.jar', discovered_models[\"Palia\"], path_logB+\".xes\"])\n",
    "\n",
    "    # The total fitness value is saved in the file paliacc.txt\n",
    "    f = open(\"paliacc.txt\", \"r\")\n",
    "    for line in f:\n",
    "        ccpalia = float(line)\n",
    "    f.close()\n",
    "\n",
    "    ccpalia_traces = pd.read_csv(\"Accepted Traces/accepted_traces_palia_\"+uuid+\".csv\", names=[\"id\",\"fitness\"])\n",
    "    res = res.assign(ccpalia = ccpalia_traces.loc[:,\"fitness\"])\n",
    "    print(\"Done\")\n",
    "\n",
    "    # Conformance of frequency\n",
    "    print(\"Conformance of frequency...\")\n",
    "    ccfreq_ev, ccfreq_t, ccfreq = get_freq_fitness(discovered_models[\"Freq\"], logA, logB)\n",
    "    ccfreq_traces = pd.DataFrame(ccfreq_t.items(), columns=[\"id\", \"fitness\"])\n",
    "    res = res.assign(ccfreq = ccfreq_traces.loc[:,\"fitness\"])\n",
    "    ccfreq_traces.to_csv(\"Accepted Traces/accepted_traces_freq_\"+uuid+\".csv\")\n",
    "    print(\"Done\")\n",
    "\n",
    "    # Conformance of duration\n",
    "    if(not discovered_models[\"Dur\"] is None):\n",
    "        print(\"Conformance of duration...\")\n",
    "        ccdur_ev, ccdur_t, ccdur = get_duration_fitness(discovered_models[\"Dur\"], logA, logB)\n",
    "        ccdur_traces = pd.DataFrame(ccdur_t.items(),columns=[\"id\", \"fitness\"])\n",
    "        res = res.assign(ccdur = ccdur_traces.loc[:,\"fitness\"])\n",
    "        ccdur_traces.to_csv(\"Accepted Traces/accepted_traces_dur_\"+uuid+\".csv\")\n",
    "        print(\"Done\")\n",
    "    else: ccdur = \"\"\n",
    "\n",
    "    # Get fitness of absolute time\n",
    "    if(not discovered_models[\"AbsT\"] is None):\n",
    "        print(\"Absolute time comparison...\")\n",
    "        cctime_act, cctime = get_time_fitness(logA, logB)\n",
    "        print(\"Done\")\n",
    "    else: cctime = \"\"\n",
    "\n",
    "    # Get fitness of events positions\n",
    "    print(\"Position frequency comparison...\")\n",
    "    ccpos_t, ccpos = get_position_fitness(discovered_models[\"Pos\"], logB)\n",
    "    ccpos_traces = pd.DataFrame(ccpos_t.items(),columns=[\"id\", \"fitness\"])\n",
    "    res = res.assign(ccpos = ccpos_traces.loc[:,\"fitness\"])\n",
    "    ccpos_traces.to_csv(\"Accepted Traces/accepted_traces_pos_\"+uuid+\".csv\")\n",
    "    print(\"Done\")\n",
    "\n",
    "    # Get fitness of trace length\n",
    "    print(\"Trace length comparison...\")\n",
    "    cclen_t, cclen = get_length_fitness(discovered_models[\"Len\"], logB)\n",
    "    cclen_traces = pd.DataFrame(data=cclen_t.items(),columns=[\"id\", \"fitness\"])\n",
    "    res = res.assign(cclen = cclen_traces.loc[:,\"fitness\"])\n",
    "    res = res.assign(id = cclen_traces.loc[:,\"id\"])\n",
    "    cclen_traces.to_csv(\"Accepted Traces/accepted_traces_len_\"+uuid+\".csv\")\n",
    "    print(\"Done\")\n",
    "\n",
    "    res.index += 1 \n",
    "    other, final_output = compute_fitness_values(res, pm4py.convert_to_dataframe(logB), 1)\n",
    "    other.to_csv(\"Results.csv\")\n",
    "    write_xes(pm4py.convert_to_event_log(final_output), path_output+\".xes\")\n",
    "\n",
    "    header = [\"logA\", \"logB\", \"CCHeu\", \"CCInd\", \"CCDcr\",\"CCPalia\", \"CCFreq\", \"CCDur\", \"CCTime\", \"CCPos\", \"CCLen\"]\n",
    "    values = [path_logA, path_logB, ccheu, ccind, ccdcr, ccpalia, ccfreq, ccdur, cctime, ccpos, cclen]\n",
    "    print(\"Writing the results...\")\n",
    "    # open the file in the write mode\n",
    "\n",
    "    # Create File\n",
    "    if not os.path.exists('Results.csv'):\n",
    "        print(\"Creating file...\")\n",
    "        with open('Results.csv', 'w', newline=\"\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(header)\n",
    "            writer.writerow(values)\n",
    "            print(\"Done\")\n",
    "    else:\n",
    "        with open('Results.csv', 'a', newline=\"\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(values)\n",
    "            print(\"Done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Classify.bat logs\\test\\test-log logs\\base\\base-log models\\discovered-model logs\\classified\\test-log\n",
    "if __name__ == \"__main__\":\n",
    "    A = sys.argv[1]\n",
    "    B = sys.argv[2]\n",
    "    C = sys.argv[3]\n",
    "    D = sys.argv[4]\n",
    "    execall(A,B,C,D)\n",
    "    print(\"####################\")\n",
    "    print(\"TASKS COMPLETED\")\n",
    "    print(\"####################\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
